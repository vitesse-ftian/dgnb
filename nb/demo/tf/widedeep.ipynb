{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Wide and Deep Tutorial\n",
    "This notebook demos how to run tensorflow [wide](https://www.tensorflow.org/tutorials/wide)\n",
    "and [wide and deep](https://www.tensorflow.org/tutorials/wide_and_deep) tutorial.\n",
    "\n",
    "You should run [load](./widedeep_load.ipynb) before playing with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# As usural, we open a database connection.   \n",
    "import dg.conn\n",
    "import dg.xtable\n",
    "import dg.tf.estimator\n",
    "\n",
    "con = dg.conn.Conn(user=\"ftian\")\n",
    "print (con.ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data and test data\n",
    "xt1 = dg.xtable.fromTable(con, 'widedeep_train')\n",
    "xt2 = dg.xtable.fromTable(con, 'widedeep_test')\n",
    "xt2 = xt2.select(where=\"\"\"gender = 'Male'\"\"\")\n",
    "xt2 = xt2.select(select='''\n",
    "    age, workclass, fnlwgt, education, education_num, \n",
    "    marital_status, occupation, relationship, race, \n",
    "    'Female'::text as gender, \n",
    "    capital_gain, capital_loss, hours_per_week, native_country,\n",
    "    income\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build estimator\n",
    "est = dg.tf.estimator.Estimator()\n",
    "\n",
    "# We want some more info from eval/predicate than the original tutorial.  true/flase x pos/neg\n",
    "est.add_out_col('falseneg', 'int')\n",
    "est.add_out_col('trueneg', 'int')\n",
    "est.add_out_col('falsepos', 'int')\n",
    "est.add_out_col('truepos', 'int')\n",
    "est.add_out_col('accuracy', 'float')\n",
    "\n",
    "# If you change this nround, better change the CONF_nround in tfcode below as well.\n",
    "CONF_nround = 2\n",
    "\n",
    "# Let's repeat xt1 2 x 5 times, then eval.  you can change \n",
    "for ii in range(CONF_nround):\n",
    "    est.tfinput.add_xt(xt1, repeat=5)\n",
    "    est.tfinput.add_xt(xt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf code is tensorflow code.  The following code largely copy/pasted from \n",
    "# original google tensorflow example, with minor modifications.\n",
    "# Most important of all, the input functions are changed to get data from \n",
    "# database.   Then output instead of printing, we return true/false * pos/neg\n",
    "# and accuracy.\n",
    "# \n",
    "# Instead of paring command line, we just fix CONF_xxx value.  \n",
    "#\n",
    "# indent is 4 spaces, as it should be.\n",
    "#\n",
    "# License/Copyright omitted -- see original tutorial link and all credit goes there.\n",
    "# \n",
    "\n",
    "tfcode = \"\"\"\n",
    "import shutil\n",
    "\n",
    "CONF_nround = 2                     # Match the value in notebook.\n",
    "CONF_dir = '/tmp/census_model'\n",
    "CONF_rmdir = True\n",
    "CONF_model = 'wide_deep'            # can be 'wide', 'deep', 'wide_deep' \n",
    "\n",
    "def build_model_columns():\n",
    "    # Continuous columns\n",
    "    age = tf.feature_column.numeric_column('age')\n",
    "    education_num = tf.feature_column.numeric_column('education_num')\n",
    "    capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "    capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "    hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n",
    "\n",
    "    education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'education', [\n",
    "          'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',\n",
    "          'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',\n",
    "          '5th-6th', '10th', '1st-4th', 'Preschool', '12th'])\n",
    "\n",
    "    marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      'marital_status', [\n",
    "          'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',\n",
    "          'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])\n",
    "\n",
    "    relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'relationship', [\n",
    "          'Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried',\n",
    "          'Other-relative'])\n",
    "          \n",
    "    gender = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'gender', ['Male', 'Female'])\n",
    "        \n",
    "    workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      'workclass', [\n",
    "          'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',\n",
    "          'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])\n",
    "\n",
    "    # To show an example of hashing:\n",
    "    occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'occupation', hash_bucket_size=1000)\n",
    "\n",
    "    # Transformations.\n",
    "    age_buckets = tf.feature_column.bucketized_column(\n",
    "        age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "\n",
    "    # Wide columns and deep columns.\n",
    "    base_columns = [\n",
    "        education, marital_status, relationship, workclass, occupation,\n",
    "        gender,\n",
    "        age_buckets, \n",
    "    ]\n",
    "\n",
    "    crossed_columns = [\n",
    "        tf.feature_column.crossed_column(\n",
    "            ['education', 'occupation'], hash_bucket_size=1000),\n",
    "            tf.feature_column.crossed_column(\n",
    "            [age_buckets, 'education', 'occupation'], hash_bucket_size=1000),\n",
    "    ]\n",
    "\n",
    "    wide_columns = base_columns + crossed_columns\n",
    "\n",
    "    deep_columns = [\n",
    "        age,\n",
    "        education_num,\n",
    "        capital_gain,\n",
    "        capital_loss,\n",
    "        hours_per_week,\n",
    "        tf.feature_column.indicator_column(workclass),\n",
    "        tf.feature_column.indicator_column(education),\n",
    "        tf.feature_column.indicator_column(marital_status),\n",
    "        tf.feature_column.indicator_column(relationship),\n",
    "        # To show an example of embedding\n",
    "        tf.feature_column.embedding_column(occupation, dimension=8),\n",
    "    ]\n",
    "    return wide_columns, deep_columns\n",
    "        \n",
    "def build_estimator(model_dir, model_type):\n",
    "    wide_columns, deep_columns = build_model_columns()\n",
    "    hidden_units = [100, 75, 50, 25]\n",
    "    # Create a tf.estimator.RunConfig to ensure the model is run on CPU, which\n",
    "    # trains faster than GPU for this model.\n",
    "    run_config = tf.estimator.RunConfig().replace(\n",
    "        session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "    if model_type == 'wide':\n",
    "        return tf.estimator.LinearClassifier(\n",
    "            model_dir=model_dir,\n",
    "            feature_columns=wide_columns,\n",
    "            config=run_config)\n",
    "    elif model_type == 'deep':\n",
    "        return tf.estimator.DNNClassifier(\n",
    "            model_dir=model_dir,\n",
    "            feature_columns=deep_columns,\n",
    "            hidden_units=hidden_units,\n",
    "            config=run_config)\n",
    "    else:\n",
    "        return tf.estimator.DNNLinearCombinedClassifier(\n",
    "            model_dir=model_dir,\n",
    "            linear_feature_columns=wide_columns,\n",
    "            dnn_feature_columns=deep_columns,\n",
    "            dnn_hidden_units=hidden_units,\n",
    "            config=run_config)\n",
    "\n",
    "def input_fn(ii, cache_rs=False):\n",
    "    features = sql_input_fn(ii, cache_rs)\n",
    "    labels = features.pop('income')\n",
    "    return features, tf.equal(labels, '>50K')\n",
    "\n",
    "def array_input_fn(features):\n",
    "    return features.pop('income'), None\n",
    "\n",
    "def main(unused_args): \n",
    "    # Clean up the model directory if present\n",
    "    if CONF_rmdir:\n",
    "        shutil.rmtree(CONF_dir, ignore_errors=True)\n",
    "    model = build_estimator(CONF_dir, CONF_model)\n",
    "\n",
    "    for ii in range(CONF_nround): \n",
    "        model.train(input_fn=lambda: input_fn(ii*2))\n",
    "\n",
    "        sql_clear_cached_rs()\n",
    "        predict_res = model.predict(input_fn=lambda: input_fn(ii*2+1, cache_rs=True)) \n",
    "        predict_input = sql_cached_rs()\n",
    "        falseneg, trueneg, falsepos, truepos = 0, 0, 0, 0\n",
    "        idx = 0\n",
    "        for predict in predict_res:\n",
    "            data = predict_input[idx][-1]\n",
    "            res = predict['class_ids'][0]\n",
    "            idx += 1\n",
    "            if data == '>50K':\n",
    "                if res == 0:\n",
    "                    falseneg += 1\n",
    "                elif res == 1:\n",
    "                    truepos += 1\n",
    "                else:\n",
    "                    raise ValueError(\"Bad result >50K?  [\" + data + \"] classified as \" + str(res))\n",
    "            elif data == '<=50K':\n",
    "                if res == 0:\n",
    "                    trueneg += 1\n",
    "                elif res == 1:\n",
    "                    falsepos += 1\n",
    "                else:\n",
    "                    raise ValueError(\"Bad result <=50K? [\" + data + \"] classified as \" + str(res))\n",
    "            else:\n",
    "                raise ValueError(\"Bad result? [\" + data + \"] classified as \" + str(res))\n",
    "\n",
    "        vitessedata.phi.WriteOutput([falseneg, trueneg, falsepos, truepos, \n",
    "                        float(trueneg + truepos) / float(trueneg + truepos + falseneg + falsepos)]) \n",
    "    vitessedata.phi.WriteOutput(None)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+------------+\n",
      "|   falseneg |   trueneg |   falsepos |   truepos |   accuracy |\n",
      "|------------+-----------+------------+-----------+------------|\n",
      "|       1680 |      7157 |        447 |      1576 |   0.804144 |\n",
      "|       1550 |      7077 |        527 |      1706 |   0.808748 |\n",
      "+------------+-----------+------------+-----------+------------+\n"
     ]
    }
   ],
   "source": [
    "# Run the tensorflow code.\n",
    "est.add_tf_code(tfcode)\n",
    "estxt = est.build_xt(con)\n",
    "print (estxt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
