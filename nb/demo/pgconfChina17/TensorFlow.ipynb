{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Example\n",
    "\n",
    "While both training and tagging works.  I doubt data scientists will really use the training example to train their model -- but for serving, I believe it is a no brainer.\n",
    "\n",
    "Anyway, the following is the tensorflow tagging example.  \n",
    "\n",
    "The tf_h3.sql and tf_h3_ps.sql can be used to train the model.  In general, one should start two sql sessions, on running tf_h3.sql and one running tf_h3_ps.sql.   User can run the the following eval during the training and can see the accuracy of the model changes during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: ftian@ftian'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we connect to database.\n",
    "%load_ext sql\n",
    "%sql postgresql://ftian@localhost/ftian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalsql = \"\"\"\n",
    "select count(*) from (\n",
    "select \n",
    "dg_utils.transducer_column_int4(1) as prediction,\n",
    "dg_utils.transducer_column_int4(2) as data_tag, \n",
    "dg_utils.transducer_column_float4(3) as data_cat, \n",
    "dg_utils.transducer_column_float4(4) as data_x, \n",
    "dg_utils.transducer_column_float4(5) as data_y,\n",
    "dg_utils.transducer($PHIWORKER$PhiExec python2\n",
    "import vitessedata.phi\n",
    "import tensorflow.python.platform\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "vitessedata.phi.DeclareTypes('''\n",
    "//\n",
    "// BEGIN INPUT TYPES\n",
    "// tag int32\n",
    "// cat float32\n",
    "// x float32\n",
    "// y float32\n",
    "// END INPUT TYPES\n",
    "//\n",
    "// BEGIN OUTPUT TYPES\n",
    "// predication int32\n",
    "// tag int32\n",
    "// cat float32\n",
    "// x float32\n",
    "// y float32\n",
    "// END OUTPUT TYPES\n",
    "//\n",
    "''')\n",
    "\n",
    "# Global variables.\n",
    "NUM_LABELS = 2    # The number of labels.\n",
    "NUM_FEATURES = 3  # The number of features\n",
    "BATCH_SIZE = 100  # The number of training examples to use per training step.\n",
    "NUM_HIDDEN = 20\n",
    "\n",
    "def nextbatch(): \n",
    "    labels = []\n",
    "    fvecs = []\n",
    "    recs = []\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        if cnt == BATCH_SIZE:\n",
    "            break\n",
    "        rec = vitessedata.phi.NextInput()\n",
    "        if not rec:\n",
    "            break\n",
    "        cnt += 1\n",
    "        labels.append(rec[0])\n",
    "        fvecs.append([rec[1], rec[2], rec[3]]) \n",
    "        recs.append(rec)\n",
    "\n",
    "    if cnt == 0:\n",
    "        return cnt, None, None, None\n",
    "    else:\n",
    "        # Convert the array of float arrays into a numpy float matrix.\n",
    "        fvecs_np = np.matrix(fvecs).astype(np.float32)\n",
    "\n",
    "        # Convert the array of int labels into a numpy array.\n",
    "        labels_np = np.array(labels).astype(dtype=np.uint8)\n",
    "\n",
    "        # Convert the int numpy array into a one-hot matrix.\n",
    "        labels_onehot = (np.arange(NUM_LABELS) == labels_np[:, None]).astype(np.float32)\n",
    "        return cnt, recs, fvecs_np, labels_onehot\n",
    "\n",
    "# Init weights method. (Lifted from Delip Rao: http://deliprao.com/archives/100)\n",
    "def init_weights(shape, init_method='xavier', xavier_params = (None, None)):\n",
    "    if init_method == 'zeros':\n",
    "        return tf.Variable(tf.zeros(shape, dtype=tf.float32))\n",
    "    elif init_method == 'uniform':\n",
    "        return tf.Variable(tf.random_normal(shape, stddev=0.01, dtype=tf.float32))\n",
    "    else: #xavier\n",
    "        (fan_in, fan_out) = xavier_params\n",
    "        low = -4*np.sqrt(6.0/(fan_in + fan_out)) # {sigmoid:4, tanh:1} \n",
    "        high = 4*np.sqrt(6.0/(fan_in + fan_out))\n",
    "        return tf.Variable(tf.random_uniform(shape, minval=low, maxval=high, dtype=tf.float32))\n",
    "\n",
    "def main(_): \n",
    "    global_step = tf.Variable(0, trainable=False) \n",
    "\n",
    "    # This is where training samples and labels are fed to the graph.\n",
    "    # These placeholder nodes will be fed a batch of training data at each\n",
    "    # training step using the {feed_dict} argument to the Run() call below.\n",
    "    x = tf.placeholder(\"float\", shape=[None, NUM_FEATURES])\n",
    "    y_ = tf.placeholder(\"float\", shape=[None, NUM_LABELS])\n",
    "    \n",
    "    # Define and initialize the network.\n",
    "    # Initialize the hidden weights and biases.\n",
    "    w_hidden = init_weights(\n",
    "        [NUM_FEATURES, NUM_HIDDEN], \n",
    "        'xavier', xavier_params=(NUM_FEATURES, NUM_HIDDEN)) \n",
    "\n",
    "    b_hidden = init_weights([1,NUM_HIDDEN],'zeros') \n",
    "    # The hidden layer.\n",
    "    hidden = tf.nn.tanh(tf.matmul(x,w_hidden) + b_hidden)\n",
    "\n",
    "    # Initialize the output weights and biases.\n",
    "    w_out = init_weights(\n",
    "            [NUM_HIDDEN, NUM_LABELS],\n",
    "            'xavier', xavier_params=(NUM_HIDDEN, NUM_LABELS))\n",
    "\n",
    "    b_out = init_weights([1,NUM_LABELS],'zeros')\n",
    "\n",
    "    # The output layer.\n",
    "    y = tf.nn.softmax(tf.matmul(hidden, w_out) + b_out)\n",
    "\n",
    "    # Optimization.\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy, global_step=global_step)\n",
    "    \n",
    "    # Evaluation.\n",
    "    predicted_class = tf.argmax(y,1);\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    init_op = tf.global_variables_initializer() \n",
    "\n",
    "    sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "    saver = tf.train.Saver()\n",
    "    sess = tf.Session(config=sess_config)\n",
    "    ckpt = tf.train.get_checkpoint_state(\"/home/ftian/oss/dgtools/demo/upwork/tensorflow/h3_log_0/\")\n",
    "    if ckpt:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path) \n",
    "    else:\n",
    "        return\n",
    "    while True:\n",
    "        cnt, inrecs, test_data, test_labels = nextbatch()\n",
    "        if cnt == 0:\n",
    "            logging.info(\"empty batch, done.\")\n",
    "            break\n",
    "        else:\n",
    "            p, gstep = sess.run([predicted_class, global_step], feed_dict={x: test_data, y_: test_labels})\n",
    "            for i in range(cnt):\n",
    "                rec = inrecs[i]\n",
    "                outrec = [p[i], rec[0], rec[1], rec[2], rec[3]]\n",
    "                vitessedata.phi.WriteOutput(outrec)\n",
    "\n",
    "    logging.info(\"Flushing ...\")\n",
    "    vitessedata.phi.WriteOutput(None)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "\n",
    "$PHIWORKER$), tworker.*\n",
    "\n",
    "from ( select tag, \n",
    "       case when cat = 'linear' then 1.0::float4\n",
    "            when cat = 'moon' then 2.0::float4\n",
    "            else 3.0::float4 end,\n",
    "       x::float4, y::float4 from tf_eval ) tworker\n",
    ") tf \n",
    "where prediction <> data_tag\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 rows affected.\n",
      "+-------+\n",
      "| count |\n",
      "+-------+\n",
      "|   63  |\n",
      "+-------+\n"
     ]
    }
   ],
   "source": [
    "rows = %sql $evalsql\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
